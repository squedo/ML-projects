{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pkg and methods\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# getting the data from df_train and splitting between X_train and y_train => we could use as well train_test_split method\n",
    "train_data = df_train.values\n",
    "X_train = train_data[:,0:df_train.shape[1]-1]\n",
    "y_train = train_data[:,df_train.shape[1]-1]\n",
    "\n",
    "# Now Scaling and fitting model with training data X_train and y_train\n",
    "X_train = StandardScaler().fit(X_train).transform(X_train)\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "# Using X_test and y_test to check the model\n",
    "test_data = df_test.values\n",
    "X_test = test_data[:,0:df_test.shape[1]-1]\n",
    "y_test = test_data[:,df_test.shape[1]-1]\n",
    "\n",
    "X_test = StandardScaler().fit(X_test).transform(X_test)\n",
    "y_hat = lr.predict(X_test)\n",
    "\n",
    "# Calculating metrics of the model\n",
    "print('Mean squared error for test data = ', mean_squared_error(y_test,y_hat, squared = True))\n",
    "print('Mean root squared logarithmic error for test data = ', mean_squared_log_error(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading modeling methods to build our multiple linear regression model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We get the data from the dataframe df_model\n",
    "data = df_model.values\n",
    "\n",
    "# Normalizing data\n",
    "dataNorm = StandardScaler().fit(data).transform(data)\n",
    "\n",
    "# Distinguishing between feature and predicted values\n",
    "X = dataNorm[:,0:dataNorm.shape[1]-1]\n",
    "y = data[:,dataNorm.shape[1]-1]\n",
    "\n",
    "# As follows we build the model, and will split the data 25 times to proceed with the model score calculation.\n",
    "# Finally we will bring provide an average variance score on 25 random splits. The closer to 1, the best.\n",
    "score = [];\n",
    "\n",
    "for i in range(0,25):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=True);\n",
    "\n",
    "    lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "    value = lr.score(X_test,y_test) # Explained variance score: 1 is perfect prediction\n",
    "    \n",
    "    score.append(value)\n",
    "\n",
    "print('Average variance score on 25 random splits = ', np.round(np.mean(score),decimals = 3))\n",
    "\n",
    "# We calculate predicted values for 1 split\n",
    "y_hat = lr.predict(X_test)\n",
    "\n",
    "# Visualizing model prediction and real values to have an idea on how closer we are.\n",
    "# Clearly, the best scenario would be to have a line y = x\n",
    "plt.rcParams['figure.figsize'] = (14,8)\n",
    "\n",
    "plt.plot(y_test,y_hat,'g+');\n",
    "plt.xlabel('Real test values')\n",
    "plt.ylabel('Predicted test values')\n",
    "plt.title('Real CO2 emission vs calculated CO2 emissions of the cars => '+'Slope = '+str(np.round(m,decimals = 2))+' and intercept = '\n",
    "          +str(np.round(b,decimals = 2)))\n",
    "\n",
    "m, b = np.polyfit(y_test,y_hat,1)\n",
    "plt.plot(y_test, m*y_test + b,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing X\n",
    "X = StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# Setting training and test data from the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, shuffle=True);\n",
    "X_train = np.around(X_train, decimals = 5)\n",
    "X_test = np.around(X_test, decimals = 5)\n",
    "\n",
    "# We train the binary logistic regression model and fit\n",
    "clf = LogisticRegression(solver='lbfgs',max_iter=3000).fit(X_train, y_train)\n",
    "    \n",
    "# Predicted values from X_test\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "prec = average_precision_score(y_test, y_hat, average='macro')\n",
    "rec = recall_score(y_test, y_hat, average='macro')\n",
    "f1scor = f1_score(y_test,y_hat,average='binary') # for threshold in prediction of 0.5 or 50% (default)\n",
    "print('Accuracy = ', acc)\n",
    "    \n",
    "# We will now calculate the ROC AUC and plot it\n",
    "# Learn to predict each class against the other\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve, ROC area and plot it => ROC AUC is to be calculated as well in binary log regression models and analysis\n",
    "# with precision and recall obtained + accuracy and check cm to see if we are classifying in all classes.\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('ROC AUC: ', roc_auc)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC AUC for binary logistic regression ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a function for reusage inside a same script => we could include confusion matrix calculation (indeed, confusion_matrix is already loaded)\n",
    "def logRegr(X,y,test_size,max_iter):\n",
    "\n",
    "    #!pip install scikit-learn\n",
    "    #import sklearn\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.metrics import average_precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    # Normalizing X\n",
    "    X = StandardScaler().fit(X).transform(X);\n",
    "\n",
    "    # Setting training and test data from the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle=True);\n",
    "    X_train = np.around(X_train, decimals = 3);\n",
    "    X_test = np.around(X_test, decimals = 3);\n",
    "\n",
    "    # We train the binary logistic regression model and fit\n",
    "    clf = LogisticRegression(solver='lbfgs',max_iter=max_iter).fit(X_train, y_train);\n",
    "    \n",
    "    # Predicted values from X_test\n",
    "    y_hat = clf.predict(X_test);\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_hat)\n",
    "    prec = average_precision_score(y_test, y_hat, average='macro')\n",
    "    rec = recall_score(y_test, y_hat, average='macro')\n",
    "    f1scor = f1_score(y_test,y_hat,average='binary')\n",
    "    \n",
    "    # We will now calculate the ROC AUC and plot it\n",
    "    # Learn to predict each class against the other\n",
    "    y_score = clf.fit(X_train, y_train).decision_function(X_test);\n",
    "\n",
    "    # Compute ROC curve, ROC area and plot it\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score);\n",
    "    roc_auc = auc(fpr, tpr);\n",
    "    print('ROC AUC: ', roc_auc)\n",
    "\n",
    "    plt.figure();\n",
    "    lw = 2;\n",
    "    plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc);\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--');\n",
    "    plt.xlim([0.0, 1.0]);\n",
    "    plt.ylim([0.0, 1.05]);\n",
    "    plt.xlabel('False Positive Rate');\n",
    "    plt.ylabel('True Positive Rate');\n",
    "    plt.title('ROC AUC for binary logistic regression ');\n",
    "    plt.legend(loc=\"lower right\");\n",
    "    plt.show()\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_hat))\n",
    "    \n",
    "    return[acc, prec, rec, f1scor, X_train, X_test, y_train, y_test, y_hat];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import some methods that will be used\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Get the data from the df\n",
    "data = df.to_numpy()\n",
    "\n",
    "# We get in variable X all the variables data and normalize them\n",
    "X = data[:,0:data.shape[1]-1]\n",
    "X = StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# Dependent variable to predict is stored in y\n",
    "y = data[:,data.shape[1]-1]\n",
    "\n",
    "# We make a partition of the X and y data, to have training and test data --> we use 20% of the data for test purposes and we take them randomly with shuffle = True\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "# We create the logistic regression model for this multiclass case, and we train it \n",
    "clf = LogisticRegression(multi_class = 'multinomial', solver='lbfgs').fit(X, y)\n",
    "\n",
    "# We use the model to calculate the y_hat values\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "# We calculate metrics: f1_score\n",
    "f1score = f1_score(y_test,y_hat, average = 'macro').round(decimals = 3)\n",
    "accuracy = accuracy_score(y_test,y_hat).round(decimals = 3)\n",
    "\n",
    "# We display confusion matrix to understand better where the model is working better/worst \n",
    "# Also remember a) that the diagonal shows the well classified cases b) in axis Y we have true label values and X we have predicted label values\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "cm\n",
    "# We plot the confusion matrix, that allow us to visualize where our model is behaving\n",
    "plot_confusion_matrix(clf, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "# Note that by default, the prediction is taking the label that has more probabilities.\n",
    "# By extracting the probabilities calculated using the model, we could see furthermore where the model is more confident and in which cases.\n",
    "y_hat_prob = clf.predict_proba(X_test)\n",
    "print(y_hat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages and methods\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Build the decision tree model and train it\n",
    "depth = 4 # depth of the tree\n",
    "DT = tree.DecisionTreeClassifier(criterion=\"entropy\",max_depth=depth)\n",
    "DT = DT.fit(X_train,y_train)\n",
    "    \n",
    "# Predicted values from X_test\n",
    "y_hat = DT.predict(X_test)\n",
    "\n",
    "# Getting metrics\n",
    "print(\"DecisionTrees's f1_score: \", f1_score(y_test,y_hat, average = 'macro'))\n",
    "DT_accuracy = accuracy_score(y_test,y_hat).round(decimals = 3)\n",
    "print('DT_accuracy_score = ', DT_accuracy)\n",
    "\n",
    "# Getting confusion matrix\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "print(cm)\n",
    "    \n",
    "cmfor0 = cm[0,0]/np.sum(cm[0,]); print(cmfor0)\n",
    "cmfor1 = cm[1,1]/np.sum(cm[1,]); print(cmfor1)\n",
    "\n",
    "# PLotting the tree\n",
    "plt.figure(figsize=(160,50))\n",
    "a = plot_tree(DT,\n",
    "              class_names=['Setosa','Versicolor','Virginica'],\n",
    "              feature_names=['sepal length','sepal width','petal.length','petal.width'],\n",
    "              filled=True, \n",
    "              rounded=True, \n",
    "              fontsize=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages and methods\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Traning and fitting the model\n",
    "SVM = SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "# Calculating predictions\n",
    "y_hat = SVM.predict(X_test)\n",
    "\n",
    "# Accuracy score for the model SVM\n",
    "SVM_accuracy = accuracy_score(y_test,y_hat).round(decimals = 3)\n",
    "print('SVM_accuracy_score = ', SVM_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
